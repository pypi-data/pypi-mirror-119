{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Change to base directory\n",
    "# Notebook does not recognize the modules for some reason\n",
    "# ONLY RUN THIS CELL ONCE\n",
    "\n",
    "os.chdir(os.path.normpath(os.getcwd() + os.sep + os.pardir))\n",
    "os.getcwd()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyzing Predicted Captions with BLEU Scores\n",
    "Bilingual evaluation understudy (BLEU) [\"is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another.\"](https://en.wikipedia.org/wiki/BLEU)\n",
    "\n",
    "BLEU-n scores range between 0 and 1, 0 being a mismatch and 1 being a perfect match. For each image, we calculate the independent and cumulative BLEU scores (with a method 1 smoothing function) of all 5 reference captions to the predicted candidate caption.\n",
    "\n",
    "[BLEU Paper](https://aclanthology.org/P02-1040.pdf)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "%matplotlib inline\n",
    "\n",
    "from src.analysis.bleu_scores import get_bleu_scores\n",
    "from src.analysis.visualize import show_10_images_and_captions_grid, bleu_score_histogram\n",
    "from src.data.load_data import load_test, load_predictions, load_idx_word_dicts\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_, captions_test, images_test = load_test()\n",
    "idx_to_word, _ = load_idx_word_dicts()\n",
    "captions_word = [[idx_to_word.get(key) for key in caption] for caption in captions_test]\n",
    "\n",
    "predictions_word = load_predictions()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "show_10_images_and_captions_grid(images_test, predictions_word, encoded=False, file_name='predictions.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Captions length {}, predictions length {}\".format(len(captions_word), len(predictions_word)))\n",
    "\n",
    "print(\"First caption {}\".format(captions_word[0]))\n",
    "print(\"First prediction {}\".format(predictions_word[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "independent_bleu_scores = get_bleu_scores(captions_word, predictions_word, smoothing=1, independent = True)\n",
    "cumulative_bleu_scores = get_bleu_scores(captions_word, predictions_word, smoothing=1, independent = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusions\n",
    "The independent BLEU-1 scores (using 1-grams) are the highest with a mean of 0.72 and maximum of 0.97. As BLEU-n increases, the scores decrease slightly. This means that the model is slightly better at replicating certain key words than at replicating the word order or set of 2-4 words in a row.\n",
    "\n",
    "The distribution of the scores can be seen in the histograms below. The cumulative BLEU-n scores have a similar distribution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Summary of Independent scores\")\n",
    "print(independent_bleu_scores.describe().loc[['mean','max'],:])\n",
    "\n",
    "print(\"Summary of Cumulative scores\")\n",
    "print(cumulative_bleu_scores.describe().loc[['mean','max'],:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Independent BLEU Histogram\")\n",
    "bleu_score_histogram(independent_bleu_scores, \"independent_bleu.png\")\n",
    "print(\"Cumulative BLEU Histogram\")\n",
    "bleu_score_histogram(cumulative_bleu_scores, \"cumulative_bleu.png\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pttrns_py3.8': conda)"
  },
  "interpreter": {
   "hash": "8daba3ef233ea65dc4321cd4586b857cb1379d3af34090305fb62f78148b332c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}