Theory
======

REPRISE, a REtrospective and PRospective Inference SchEme, learns temporal event-predictive models of dynamical systems [1]_.
REPRISE infers the unobservable contextual event state and accompanying temporal predictive models that best explain the recently encountered sensorimotor experiences retrospectively.
Meanwhile, it optimizes upcoming motor activities prospectively in a goal-directed manner.
Here, REPRISE is implemented by a recurrent neural network (RNN), which learns temporal forward models of the sensorimotor contingencies generated by different simulated dynamic vehicles.
The RNN is augmented with contextual neurons, which enable the encoding of distinct, but related, sensorimotor dynamics as compact event codes.

.. figure:: reprise.png
   :scale: 50 %
   :alt: map to buried treasure

   Illustration of REPRISE for two consecutive time steps :math:`t` (top part) and :math:`t + 1` (bottom part).
   Note that there is only one RNN, whose activities :math:`\sigma` are buffered over time.
   The right (green shaded) boxes illustrate future imaginations actively inferring prospective motor activities, while the left boxes (gray shaded) show retrospections about the recent past for system state inference (including event state :math:`c^{t'}` and hidden state :math:`\sigma^t`).
   Black lines indicate context and information forward flow, while the red lines indicate gradient flow.
   :math:`\tilde{x}^{t'}` and :math:`\tilde{c}^{t'}` refer to the action and context input vectors, respectively, for a particular time step :math:`t'`.
   :math:`\tilde{s}^{t'}_Ï„` refers to a particular sensory prediction in the :math:`\tau`-th optimization cycle, whereas s refers to a desired sensory goal state.

References
----------

.. [1] Butz, M. V., Bilkey, D., Humaidan, D., Knott, A., & Otte, S. (2019). Learning, planning, and control in a monolithic neural event inference architecture. Neural Networks, 117, 135-144.
