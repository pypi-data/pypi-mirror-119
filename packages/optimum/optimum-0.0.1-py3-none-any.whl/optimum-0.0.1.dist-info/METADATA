Metadata-Version: 2.1
Name: optimum
Version: 0.0.1
Summary: Optimum Library is an extension of the Hugging Face Transformers library, providing a framework to integrate third-party libraries from Hardware Partners and interface with their specific functionality.
Home-page: https://huggingface.co/hardware
Author: HuggingFace Inc. Special Ops Team
Author-email: hardware@huggingface.co
License: Apache
Keywords: transformers,quantization,pruning,training,ipu
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: coloredlogs
Requires-Dist: sympy
Requires-Dist: transformers (>=4.9.2)
Requires-Dist: torch (>=1.8)
Provides-Extra: intel
Requires-Dist: pycocotools ; extra == 'intel'
Requires-Dist: lpot (>=1.6) ; extra == 'intel'
Requires-Dist: huggingface-hub ; extra == 'intel'
Requires-Dist: datasets (>=1.2.1) ; extra == 'intel'
Provides-Extra: onnxruntime
Requires-Dist: onnx ; extra == 'onnxruntime'
Requires-Dist: onnxruntime ; extra == 'onnxruntime'

[![ONNX Runtime](https://github.com/huggingface/optimum/actions/workflows/test-onnxruntime.yml/badge.svg)](https://github.com/huggingface/optimum/actions/workflows/test-onnxruntime.yml)
[![LPOT](https://github.com/huggingface/optimum/actions/workflows/test-intel.yml/badge.svg)](https://github.com/huggingface/optimum/actions/workflows/test-intel.yml)

# Optimum

## Install
To install the latest release of this package:

`pip install optimum`

or from current main branch:

`pip install https://github.com/huggingface/optimum.git`

or for development, clone the repo and install it from the local copy:

```
git clone https://github.com/huggingface/optimum.git
cd optimum 
pip install -e .
```


## Usage
Convert a hub model:
`optimum_convert` 

Optimize a hub model:
`optimum_optimize` 

Apply LPOT quantization:

```bash
python examples/pytorch/text-classification/run_glue.py \
    --model_name_or_path textattack/bert-base-uncased-SST-2 \
    --task_name sst2 \
    --provider lpot \
    --quantize \
    --quantization_approach dynamic \
    --config_name_or_path echarlaix/bert-base-dynamic-quant-test \
    --do_eval \
    --output_dir /tmp/sst2_output/
```


