{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuAkm2rldeUv"
      },
      "source": [
        "<p align=\"center\"><h1 align=\"center\">Flower Image Classification with Keras</h1> <h3 align=\"center\">(Prepare to deploy model and preprocessor to REST API/Web Dashboard in four easy steps...)</h3></p>\n",
        "<p align=\"center\"><img width=\"80%\" src='https://drive.google.com/thumbnail?id=1ea5R66cqAXs3g4oIeEiUUMhictrL2IBg&sz=w1200-h1200' /></p>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRFE7x5Xy05E"
      },
      "source": [
        "## **(1) Train Your Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW34PDS_ifdh",
        "outputId": "10e73548-d0ac-48a8-b32d-7fe9e264dd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Load a pretrained Keras model.\n",
        "!wget https://s3.amazonaws.com/aimodelshare.models/keras_flowermodel.h5\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('keras_flowermodel.h5')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-27 02:00:11--  https://s3.amazonaws.com/aimodelshare.models/keras_flowermodel.h5\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.11.22\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.11.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60081120 (57M) [application/x-www-form-urlencoded]\n",
            "Saving to: ‘keras_flowermodel.h5’\n",
            "\n",
            "keras_flowermodel.h 100%[===================>]  57.30M  15.8MB/s    in 4.5s    \n",
            "\n",
            "2020-10-27 02:00:17 (12.8 MB/s) - ‘keras_flowermodel.h5’ saved [60081120/60081120]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orMc2COAifcI",
        "outputId": "fe7945e0-45c5-4db3-f5dd-90a4760bad6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Keras model expects shape with samples, height, width, and channels last.\n",
        "model.input_shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 192, 192, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_I8KnSZzEHh"
      },
      "source": [
        "## **(2) Save Model to ONNX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EvgKeh-bKIU"
      },
      "source": [
        "# Load libraries for ONNX model conversion (Keras to ONNX).\n",
        "! pip3 install keras2onnx\n",
        "! pip3 install onnxruntime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZq2KfnsbJ8p",
        "outputId": "195049f0-e8e5-4873-ce2b-3236ab763893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Save model to onnx file.\n",
        "\n",
        "import os\n",
        "os.environ['TF_KERAS'] = '1' # Add this environmental variable whenever you use TensorFlow's `tf.keras` to build your Keras model.\n",
        "\n",
        "import onnx\n",
        "import keras2onnx\n",
        "\n",
        "# Convert model to onnx object.\n",
        "import onnx\n",
        "from keras2onnx import convert_keras # Specific to your architecture.\n",
        "onnx_model = convert_keras(model, 'my_model.onnx')\n",
        "\n",
        "# Save model to local .onnx file.\n",
        "with open(\"my_model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf executing eager_mode: True\n",
            "tf.keras model eager_mode: False\n",
            "The ONNX operator number change on the optimization: 49 -> 24\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWZOqwbjzp1t"
      },
      "source": [
        "## **(3) Write Preprocessor Function**\n",
        "\n",
        "> ### Preprocessor functions for image prediction models can use ***`cv2`*** and ***`numpy`*** to read in and preprocess images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPc3lTPpifYa"
      },
      "source": [
        "# Write preprocessor that will match up with model's expected input shape.\n",
        "def preprocessor(data, shape=(192, 192)):\n",
        "        \"\"\"\n",
        "        This function reads in images, resizes them to a fixed shape, and\n",
        "        min/max transforms them, before converting feature values to float32\n",
        "        for ONNX.\n",
        "        \n",
        "        params:\n",
        "            data\n",
        "                list of unprocessed images\n",
        "                      \n",
        "        returns:\n",
        "            X\n",
        "                numpy array of preprocessed image data\n",
        "                  \n",
        "        \"\"\"\n",
        "           \n",
        "        import cv2\n",
        "        import numpy as np\n",
        "\n",
        "        \"Resize a color image and min/max transform the image\"\n",
        "        img = cv2.imread(data) # Read in image from filepath.\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 reads in images in order of blue green and red, we reverse the order for ML.\n",
        "        img = cv2.resize(img, shape) # Change height and width of image.\n",
        "        img = img / 255.0 # Min-max transform.\n",
        "\n",
        "\n",
        "        # Resize the images.\n",
        "        X = np.array(img)\n",
        "        X = np.expand_dims(X, axis=0) # Expand dims to add \"1\" to object shape [1, h, w, channels].\n",
        "        X = np.array(X, dtype=np.float32) # Final shape for onnx runtime.\n",
        "        return X"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS999_Udz25e"
      },
      "source": [
        "You may want to verify that your `preprocessor` is working as intended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXChVDH0hcmi",
        "outputId": "247cabcc-fc12-4f97-9994-05923677c7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load in flower_photos.\n",
        "import pathlib\n",
        "dataset_url = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='flower_photos', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y3NMRsxjlJD",
        "outputId": "b1009d38-7549-4e3c-c5aa-2ff23a3d5f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the first roses image.\n",
        "roses = list(data_dir.glob('roses/*'))\n",
        "\n",
        "import os\n",
        "preprocessor(os.fspath(roses[0])).shape # os.fspath converts PosixPath to simple str."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 192, 192, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY0ve9d1zcq7"
      },
      "source": [
        "## **(4) Save Preprocessor Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYo-4oZibKTr"
      },
      "source": [
        "# ! pip3 install aimodelshare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5p5LsMFbKQb"
      },
      "source": [
        "def export_preprocessor(preprocessor_function, filepath):\n",
        "    import dill\n",
        "    with open(filepath, 'wb') as f:\n",
        "        dill.dump(preprocessor_function, f)\n",
        "\n",
        "# import aimodelshare as ai # Once we can deploy this, we use it in lieu of the below.\n",
        "# ai.export_preprocessor(preprocessor, \"preprocessor.pkl\")\n",
        "\n",
        "export_preprocessor(preprocessor, 'preprocessor.pkl')"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}